<div align='center'>

### <i> Criando Processos de RedundÃ¢ncia de Arquivos na Azure. </i>

<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Microsoft-Teams-Animated-Emojis/master/Emojis/Travel%20and%20places/Star.png" alt="Hand with Fingers Splayed Light Skin Tone" width="20" height="20" />
<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Microsoft-Teams-Animated-Emojis/master/Emojis/Hand%20gestures/Folded%20Hands%20Light%20Skin%20Tone.png" alt="Hand with Fingers Splayed Light Skin Tone" width="20" height="20" />

<br />

<img width="300" align="center" src="../img/microsoft-azure.png">

</div>

<br />

<div align='left'>

> #### ğŸ¯ OBJETIVO DO PROJETO

- O objetivo desse projeto Ã© criar um pipeline completo de redundÃ¢ncia de arquivos utilizando recursos do <strong>Microsoft Azure</strong>.
- Nesse redme vocÃª encontrarÃ¡ um guia de como configurar toda a infraestrutura necessÃ¡ria com <strong>Azure Data Factory</strong>, <strong>SQL Server</strong> (local e na nuvem) e <strong>Azure Data Lake (Blob Storage)</strong>, movimentando dados entre esses ambientes, criando arquivos `.txt` organizados por camadas de dados em containers (`bronze`, `prata`, `ouro`).

---

### PASSO A PASSO DA CRIAÃ‡ÃƒO DO DESAFIO <img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/People%20with%20activities/Woman%20Walking%20Medium%20Skin%20Tone.png" alt="Woman Walking Medium Skin Tone" width="25" height="25" />

</div>

<div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ”¹ Configurar a infraestrutura necessÃ¡ria no Azure Data Factory para conectar ambientes on-premises e na nuvem. </div>
<div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ”¹ Implementar a extraÃ§Ã£o de dados de uma tabela SQL Server local. </div>
<div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ”¹ Transferir esses dados para o Azure Data Lake Storage. </div>
<div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ”¹ Converter os dados em arquivos .TXT organizados em uma estrutura de camadas. </div>
<div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ”¹ Validar, publicar e executar o pipeline de dados. </div>
<div> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ğŸ”¹ Analisar a performance e aplicar boas prÃ¡tica. </div>

---

> #### âœï¸ Tipos de RedundÃ¢ncia no Azure

- O Azure oferece diferentes tipos de redundÃ¢ncia de arquivos, adequados para diversas necessidades de disponibilidade e desempenho:

  -ğŸ”¹ <strong>LRS (Locally Redundant Storage):</strong> Armazena mÃºltiplas cÃ³pias de dados dentro de um Ãºnico datacenter na regiÃ£o escolhida. Adequado para proteÃ§Ã£o contra falhas de hardware locais.

  -ğŸ”¹ <strong>GRS (Geo-Redundant Storage):</strong> RÃ©plica de dados entre datacenters em regiÃµes geograficamente isoladas, garantindo alta disponibilidade e recuperaÃ§Ã£o em caso de falhas em uma regiÃ£o inteira.

  -ğŸ”¹ <strong>ZRS (Zone-Redundant Storage):</strong> Garante redundÃ¢ncia de dados entre mÃºltiplas zonas de disponibilidade dentro de uma regiÃ£o, oferecendo proteÃ§Ã£o contra falhas de uma zona.

  -ğŸ”¹ <strong>RA-GRS (Read-Access Geo-Redundant Storage):</strong> Semelhante ao GRS, mas com a adiÃ§Ã£o de permitir o acesso de leitura aos dados replicados na regiÃ£o secundÃ¡ria, aumentando a resiliÃªncia.

  -ğŸ”¹ <strong>GRS para Blobs:</strong> Proporciona redundÃ¢ncia geogrÃ¡fica para arquivos no formato blob, garantindo que as versÃµes de backup dos dados sejam mantidas fora da regiÃ£o principal.

---

> #### âš™ï¸ ConfiguraÃ§Ã£o da RedundÃ¢ncia de Arquivos no Azure

#### 1Â° - Criar uma Conta de Armazenamento

- Acesse o portal do Azure.
- No menu de navegaÃ§Ã£o, clique em <b>Armazenamento</b> e depois em <b>Contas de Armazenamento</b>.
- Clique em <b>Adicionar</b> para criar uma nova conta de armazenamento e defina a redundÃ¢ncia de dados desejada (LRS, GRS, ZRS, etc.).

#### 2Â° - Escolher o Tipo de RedundÃ¢ncia

- Durante a criaÃ§Ã£o da conta de armazenamento, selecione o tipo de redundÃ¢ncia que atende suas necessidades. Por exemplo:
  - <b>LRS</b> para redundÃ¢ncia local.
  - <b>GRS</b> para redundÃ¢ncia geogrÃ¡fica.

#### 3Â° - ConfiguraÃ§Ã£o de Blob Storage

- Para armazenar arquivos em formato de blob, crie um <b>contÃªiner</b> dentro da conta de armazenamento.
- FaÃ§a upload dos arquivos para o contÃªiner e garanta que o acesso aos dados siga as polÃ­ticas de redundÃ¢ncia configuradas.

#### 4Â° - Monitoramento e Gerenciamento

- Utilize ferramentas como o <b>Azure Monitor</b> para acompanhar o desempenho e o estado da redundÃ¢ncia de arquivos.
- Configure alertas para receber notificaÃ§Ãµes em caso de falhas no sistema de armazenamento.

#### 5Â° - Integrar com IA

- Utilize <b>Azure Machine Learning</b> ou <b>Azure Cognitive Services</b> para aplicar modelos de IA aos dados armazenados.
- Utilize <b>Azure AI</b> para otimizar a distribuiÃ§Ã£o de dados e aplicar anÃ¡lises preditivas para melhorar o processo de redundÃ¢ncia.

---

> #### ğŸ—ï¸ ConstruÃ§Ã£o do Processo de RedundÃ¢ncia de Arquivos na Azure

#### 1Â° - Criar Recursos no Azure

- Azure Data Factory (ADF).
- Azure SQL Database.
- Azure Blob Storage.
  - Criar containers: `bronze`, `prata`, `ouro`

#### 2Â° - Preparar o Ambiente On-Premises (local)

- Ter o SQL Server local com banco e tabelas disponÃ­veis.
- Verificar acesso administrativo ao servidor para configurar o Integration Runtime.

#### 3Â° - Configurar Integration Runtime Self-hosted

- No Azure Data Factory, vÃ¡ em <b>Manage >> Integration Runtimes >> New</b>.
- Escolha <b>Self-hosted\*\* e siga o assistente:
  - Baixe o instalador (modo express ou manual).
  - Instale no servidor local (on-premises).
  - Configure com a chave gerada pelo ADF.
  - Verifique se o status estÃ¡ como â€œRunningâ€.

#### 4Â° - Criar Linked Services

##### 4.1 Para o SQL Server On-Premises

- VÃ¡ em <b>Manage >> Linked Services >> New >> SQL Server</b>.
- Utilize o Integration Runtime criado.
- Insira servidor, banco, autenticaÃ§Ã£o e teste a conexÃ£o.

##### 4.2 Para o Azure SQL Database

- Criar outro Linked Service apontando para o banco na nuvem.

##### 4.3 Para o Azure Blob Storage

- Criar um Linked Service usando a Storage Account.
- Inserir a chave de acesso da conta.

#### 5Â° - Criar Datasets

##### 5.1 Dataset de Origem

- Criar um dataset do tipo <b>SQL Server Table</b>.
- Escolher o Linked Service do SQL Server on-premises.
- Definir a tabela que serÃ¡ copiada.

##### 5.2 Dataset de Destino

- Criar um dataset do tipo <b>DelimitedText (.txt)</b>.
- Escolher o Linked Service do Blob Storage.
- Apontar para o container/caminho desejado (`bronze`, `prata`, `ouro`).
- Configurar delimitador e nome do arquivo.

#### 6Â° - Criar Pipeline de CÃ³pia

##### 6.1 Construir o Pipeline

- No Data Factory, ir para <b>Author > Pipelines > New pipeline</b>.
- Adicionar a atividade <b>Copy Data</b>.
  - <b>Source (origem)</b>: Dataset do SQL Server local.
  - <b>Sink (destino)</b>: Dataset no Blob Storage.
  - Nomear e salvar.

##### 6.2 Validar e Publicar

- Clique em <b>Validate</b> para checar erros.
- Clique em <b>Publish All</b> para aplicar mudanÃ§as.

#### 7Â° - Executar e Monitorar

##### 7.1 Executar Pipeline

- Rodar o pipeline manualmente (<strong>Debug</strong>) ou configurar um trigger (<strong>Trigger Now</strong>).

##### 7.2 Verificar Resultados

- VÃ¡ atÃ© o container do Azure Blob Storage.
- Verifique se o arquivo `.txt` foi gerado com sucesso.

##### 7.3 Analisar Performance

- No painel do Data Factory, abra a aba <b>Monitor</b>.
- Verifique duraÃ§Ã£o da execuÃ§Ã£o, throughput, logs e outras informaÃ§Ãµes.

---

> #### BenefÃ­cios da RedundÃ¢ncia de Arquivos no Azure

- <b>Alta Disponibilidade</b>: A redundÃ¢ncia assegura que os dados estejam sempre acessÃ­veis, mesmo em situaÃ§Ãµes de falha.
- <b>ProteÃ§Ã£o contra Perda de Dados</b>: Dados crÃ­ticos sÃ£o protegidos contra falhas de hardware ou problemas de infraestrutura.
- <b>Escalabilidade</b>: O Azure oferece escalabilidade para acomodar grandes volumes de dados com redundÃ¢ncia eficiente.
- <b>Custo-efetivo</b>: As soluÃ§Ãµes de redundÃ¢ncia do Azure permitem balancear custo e seguranÃ§a com opÃ§Ãµes como LRS e GRS.

---

> #### ğŸ”— Link para Administrar as aplicaÃ§Ãµes

- [Microsoft Azure](https://portal.azure.com/#home)

---

> #### ğŸ› ï¸ Ferramentas utilizadas

- ğŸŒ Microsoft Azure (ADF, SQL, Blob Storage)
- ğŸ’» SQL Server
- ğŸ’» Data Factory Integration Runtime
- ğŸ‘©ğŸ¾â€ğŸ’» Azure Portal
- ğŸ¤– VSCode

---

> #### ğŸ§© Tipo de desafio

- BÃ¡sico.

---

> #### ğŸ”— ReferÃªncias

- [Azure Storage](https://learn.microsoft.com/pt-br/azure/storage/)
- [Azure Databricks](https://azure.microsoft.com/pt-br/services/databricks/)
- [Azure Machine Learning](https://azure.microsoft.com/pt-br/services/machine-learning/)
- [Azure Monitor](https://azure.microsoft.com/pt-br/services/monitor/)

---

> #### ğŸ† CrÃ©ditos

<div align="left"> <img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Hand%20gestures/Eyes.png" alt="Hand with Fingers Splayed Light Skin Tone" width="20" height="20" /> - ver mais em <a href="https://github.com/angelicakadja">AK</a>.<img src="https://raw.githubusercontent.com/Tarikul-Islam-Anik/Animated-Fluent-Emojis/master/Emojis/Hand%20gestures/Waving%20Hand%20Medium%20Skin%20Tone.png" alt="Hand with Fingers Splayed Light Skin Tone" width="20" height="20" /></div>

</div>
